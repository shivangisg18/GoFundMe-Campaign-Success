{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "HldKjCVnpCLQ",
   "metadata": {
    "id": "HldKjCVnpCLQ"
   },
   "source": [
    "## Part E: Topic modeling (LDA) on the original image_labels \n",
    "\n",
    "For this,perform topic modeling on the image labels. This approach was chosen because the model trained exclusively on image labels achieved the best performance when the duration feature was excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "r0Y7RdedRuG0",
   "metadata": {
    "id": "r0Y7RdedRuG0"
   },
   "outputs": [],
   "source": [
    "#If Gensim is not installed, un-comment the following and run.\n",
    "\n",
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122295f9-1474-454e-b722-be24fb90b5bb",
   "metadata": {
    "id": "VKWxMzUidquv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TASK E: LDA TOPIC MODELING ON image_labels\n",
      "================================================================================\n",
      "Rows in df_clean: 997\n",
      "Vectorized image_labels -> vocab size: 460\n",
      "gensim not available: will fall back to perplexity for model selection.\n",
      "Trained k=5 | coherence=None | perplexity=61.76794518397413\n",
      "Trained k=6 | coherence=None | perplexity=61.28613182921038\n",
      "Trained k=7 | coherence=None | perplexity=60.41064585081863\n",
      "\n",
      "Model selection summary:\n",
      " k coherence  perplexity\n",
      " 5      None   61.767945\n",
      " 6      None   61.286132\n",
      " 7      None   60.410646\n",
      "\n",
      "Selected k = 7 (lowest perplexity (sklearn LDA))\n",
      "\n",
      "Top words per topic (selected model):\n",
      " Topic 1: bird, retriever, breeds, ancient, street, dog, breed, rare, beak, water\n",
      " Topic 2: horse, animal, working, livestock, snout, hedgehog, pack, supplies, mane, graphics\n",
      " Topic 3: cat, whiskers, felidae, felinae, carnivores, fur, snout, vertebrate, animal, terrestrial\n",
      " Topic 4: terrier, shelter, hound, mesh, car, greyhound, kennel, cage, small, carnivores\n",
      " Topic 5: animal, dog, snout, carnivores, working, vertebrate, canidae, fur, terrestrial, whiskers\n",
      " Topic 6: facial, happiness, expression, smile, tooth, bulldog, fun, material, tongue, natural\n",
      " Topic 7: dog, supply, carnivores, animal, canidae, snout, working, pet, collar, fur\n",
      "\n",
      "✅ Exported normalized topic proportions to: df_clean_with_normalized_topics.csv\n",
      " - Each row’s topic weights now sum to 1 exactly.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# TASK E: LDA TOPIC MODELING ON image_labels\n",
    "# ---------------------------\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# --- Ensure df_clean exists (fallback to loading file) ---\n",
    "if 'df_clean' not in globals():\n",
    "    csv_path = \"gofundme_withbinary.csv\"\n",
    "    print(f\"df_clean not found in session — loading from {csv_path}\")\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df['image_labels'] = df['image_labels'].fillna('').astype(str)\n",
    "        df['description']  = df['description'].fillna('').astype(str)\n",
    "        df['campaign_duration_days'] = df['campaign_duration_days'].fillna(df['campaign_duration_days'].median())\n",
    "        df_clean = df[df['image_labels'] != 'NO_LABELS'].copy()\n",
    "        df_clean = df_clean.reset_index(drop=True)\n",
    "        print(f\"Loaded dataset with {len(df_clean)} clean campaigns.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {csv_path} not found. Please ensure the dataset file is uploaded or generated.\")\n",
    "        exit()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TASK E: LDA TOPIC MODELING ON image_labels\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Rows in df_clean: {len(df_clean)}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Vectorize image_labels for LDA\n",
    "# ---------------------------\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=1000,\n",
    "    min_df=2,\n",
    "    stop_words='english',\n",
    "    lowercase=True\n",
    ")\n",
    "X_lda = vectorizer.fit_transform(df_clean['image_labels'].astype(str))\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "print(f\"Vectorized image_labels -> vocab size: {len(vocab)}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Tokenize for gensim\n",
    "# ---------------------------\n",
    "def tokenize_text_for_gensim(text):\n",
    "    toks = [t for t in text.lower().split() if t.isalpha() and t not in ENGLISH_STOP_WORDS]\n",
    "    return toks\n",
    "\n",
    "tokenized_docs = [tokenize_text_for_gensim(t) for t in df_clean['image_labels'].astype(str)]\n",
    "\n",
    "use_gensim = False\n",
    "try:\n",
    "    import gensim\n",
    "    from gensim.models.coherencemodel import CoherenceModel\n",
    "    dictionary = gensim.corpora.Dictionary(tokenized_docs)\n",
    "    corpus = [dictionary.doc2bow(text) for text in tokenized_docs]\n",
    "    use_gensim = True\n",
    "    print(\"gensim available: will compute coherence (c_v) for model selection.\")\n",
    "except Exception:\n",
    "    print(\"gensim not available: will fall back to perplexity for model selection.\")\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Fit LDA models and evaluate\n",
    "# ---------------------------\n",
    "results = []\n",
    "models = {}\n",
    "k_candidates = list(range(5, 8))  # 3..7\n",
    "\n",
    "for k in k_candidates:\n",
    "    lda = LatentDirichletAllocation(\n",
    "        n_components=k,\n",
    "        random_state=42,\n",
    "        learning_method='batch',\n",
    "        max_iter=20\n",
    "    )\n",
    "    lda.fit(X_lda)\n",
    "    models[k] = lda\n",
    "\n",
    "    topic_words = []\n",
    "    for comp in lda.components_:\n",
    "        top_idx = np.argsort(comp)[::-1][:10]\n",
    "        topic_words.append([vocab[i] for i in top_idx])\n",
    "\n",
    "    coherence_score = None\n",
    "    if use_gensim:\n",
    "        try:\n",
    "            cm = CoherenceModel(topics=topic_words, texts=tokenized_docs, dictionary=dictionary, coherence='c_v')\n",
    "            coherence_score = float(cm.get_coherence())\n",
    "        except Exception:\n",
    "            coherence_score = None\n",
    "\n",
    "    try:\n",
    "        perp = lda.perplexity(X_lda)\n",
    "    except Exception:\n",
    "        perp = None\n",
    "\n",
    "    results.append({'k': k, 'coherence': coherence_score, 'perplexity': perp, 'topic_words': topic_words})\n",
    "    print(f\"Trained k={k} | coherence={coherence_score} | perplexity={perp}\")\n",
    "\n",
    "res_df = pd.DataFrame([{'k': r['k'], 'coherence': r['coherence'], 'perplexity': r['perplexity']} for r in results])\n",
    "print(\"\\nModel selection summary:\")\n",
    "print(res_df.to_string(index=False))\n",
    "\n",
    "# ---------------------------\n",
    "# 4) Choose best k\n",
    "# ---------------------------\n",
    "best_k = None\n",
    "selection_reason = \"\"\n",
    "if use_gensim and res_df['coherence'].notnull().any():\n",
    "    best_k = int(res_df.loc[res_df['coherence'].idxmax(), 'k'])\n",
    "    selection_reason = \"highest coherence (c_v via gensim)\"\n",
    "else:\n",
    "    if res_df['perplexity'].notnull().any():\n",
    "        tmp = res_df[res_df['perplexity'].notnull()]\n",
    "        best_k = int(tmp.loc[tmp['perplexity'].idxmin(), 'k'])\n",
    "        selection_reason = \"lowest perplexity (sklearn LDA)\"\n",
    "    else:\n",
    "        best_k = 5\n",
    "        selection_reason = \"fallback default (5)\"\n",
    "\n",
    "print(f\"\\nSelected k = {best_k} ({selection_reason})\")\n",
    "\n",
    "selected_entry = next(r for r in results if r['k'] == best_k)\n",
    "selected_topic_words = selected_entry['topic_words']\n",
    "\n",
    "print(\"\\nTop words per topic (selected model):\")\n",
    "for i, words in enumerate(selected_topic_words):\n",
    "    print(f\" Topic {i+1}: {', '.join(words)}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Append normalized topic proportions\n",
    "# ---------------------------\n",
    "selected_lda = models[best_k]\n",
    "doc_topic = selected_lda.transform(X_lda)\n",
    "topic_cols = [f\"topic_{i+1}\" for i in range(best_k)]\n",
    "\n",
    "# Normalize each row so topic proportions sum to 1\n",
    "doc_topic = doc_topic / doc_topic.sum(axis=1, keepdims=True)\n",
    "\n",
    "df_topics = pd.DataFrame(doc_topic, columns=topic_cols, index=df_clean.index)\n",
    "for c in topic_cols:\n",
    "    df_clean[c] = df_topics[c]\n",
    "\n",
    "# ✅ Save the full df_clean with normalized topic proportions\n",
    "lda_output_csv = \"df_clean_with_normalized_topics.csv\"\n",
    "df_clean.to_csv(lda_output_csv, index=False)\n",
    "print(f\"\\n✅ Exported normalized topic proportions to: {lda_output_csv}\")\n",
    "print(\" - Each row’s topic weights now sum to 1 exactly.\")\n",
    "\n",
    "# ---------------------------\n",
    "# 6 onwards: You can keep or skip quartile analysis if needed\n",
    "# ---------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6018fad4-cc65-467c-ba90-77c047772850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Full-topic normalized comparison between fundraising quartiles ===\n",
      "     Topic  Low_Quartile_Normalized  High_Quartile_Normalized  \\\n",
      "2  topic_3                 0.300560                  0.217633   \n",
      "1  topic_2                 0.077800                  0.053134   \n",
      "0  topic_1                 0.074267                  0.065649   \n",
      "4  topic_5                 0.216696                  0.208095   \n",
      "3  topic_4                 0.049268                  0.058706   \n",
      "5  topic_6                 0.056063                  0.071548   \n",
      "6  topic_7                 0.225347                  0.325236   \n",
      "\n",
      "   Difference (High - Low)  \n",
      "2                -0.082927  \n",
      "1                -0.024665  \n",
      "0                -0.008618  \n",
      "4                -0.008600  \n",
      "3                 0.009438  \n",
      "5                 0.015485  \n",
      "6                 0.099888  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define topic columns\n",
    "topic_cols = [c for c in df_clean.columns if c.startswith(\"topic_\")]\n",
    "\n",
    "# Normalize so each row's topics sum to 1\n",
    "df_clean[topic_cols] = df_clean[topic_cols].div(df_clean[topic_cols].sum(axis=1), axis=0)\n",
    "\n",
    "# Compute quartiles by amount_raised\n",
    "q1 = df_clean['amount_raised'].quantile(0.25)\n",
    "q3 = df_clean['amount_raised'].quantile(0.75)\n",
    "\n",
    "low_q = df_clean[df_clean['amount_raised'] <= q1]\n",
    "high_q = df_clean[df_clean['amount_raised'] >= q3]\n",
    "\n",
    "# Average topic distribution across all topics for each quartile\n",
    "low_avg_vector = low_q[topic_cols].mean().values\n",
    "high_avg_vector = high_q[topic_cols].mean().values\n",
    "\n",
    "# Combine into a single dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Topic': topic_cols,\n",
    "    'Low_Quartile_Avg': low_avg_vector,\n",
    "    'High_Quartile_Avg': high_avg_vector\n",
    "})\n",
    "comparison_df['Difference (High - Low)'] = comparison_df['High_Quartile_Avg'] - comparison_df['Low_Quartile_Avg']\n",
    "\n",
    "# Normalize so the averages per group sum to 1 for full-composition comparison\n",
    "comparison_df['Low_Quartile_Normalized'] = comparison_df['Low_Quartile_Avg'] / comparison_df['Low_Quartile_Avg'].sum()\n",
    "comparison_df['High_Quartile_Normalized'] = comparison_df['High_Quartile_Avg'] / comparison_df['High_Quartile_Avg'].sum()\n",
    "\n",
    "print(\"\\n=== Full-topic normalized comparison between fundraising quartiles ===\")\n",
    "print(comparison_df[['Topic', 'Low_Quartile_Normalized', 'High_Quartile_Normalized', 'Difference (High - Low)']].sort_values(by='Difference (High - Low)'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7c181a-1ffd-4b7f-852c-3de52faa371a",
   "metadata": {},
   "source": [
    "| Topic Name                 | Interpretation                                | Difference (High–Low) | Implication |\n",
    "|-----------------------------|-----------------------------------------------|----------------------|------------|\n",
    "| Dogs & Birds (Topic 1)              | *Dog and bird imagery; breeds, rare pets*     | ~0                   | Neutral effect — images showing dogs or birds in general contexts neither significantly helped nor harmed campaign performance. |\n",
    "| Farm Animals (Topic 2)               | *Horses, livestock, rural animals*           | −0.02                | Visuals featuring livestock or less familiar animals generated lower engagement, as donors may connect less with non-companion species. |\n",
    "| Cats (Topic 3)                      | *Cat / felidae imagery*                       | −0.08                | Cat-focused images appeared more often in lower-earning campaigns, suggesting weaker emotional impact or potential donor fatigue relative to dog imagery. |\n",
    "| Shelter & Rescue Scenes (Topic 4)    | *Kennels, hounds, cages, rescue context*     | +0.01                | Showing shelter or rescue situations slightly improves engagement, signaling transparency and social responsibility. |\n",
    "| General Pet Aid (Topic 5)          | *Broad pet or working-animal imagery*        | ~0                   | Neutral — generic “pet care” photos perform moderately but lack the emotional punch of expressive or story-driven imagery. |\n",
    "| Facial Expressions (Topic 6)        | *Happiness, smiles, emotional expressiveness*| +0.02                | Positive human or animal facial expressions are associated with higher donations — images that convey joy and comfort boost emotional connection. |\n",
    "| Dogs (Topic 7)                      | *Dogs / pets / domestic companionship*       | +0.10                | Highly successful campaigns used more imagery depicting familiar pets, especially dogs, in warm, natural settings that evoke empathy and trust. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458a0114-b609-476d-b1c3-7834bb2fd15a",
   "metadata": {},
   "source": [
    "## Insights\n",
    "\n",
    "### Dog Imagery Drives Engagement\n",
    "- Campaigns with a higher share of the **Dogs** topic (+0.10) consistently raised more funds.\n",
    "- Relatable, affectionate dog photos inspire empathy and trust, making them powerful visual assets.\n",
    "\n",
    "### Emotionally Expressive Faces Matter\n",
    "- The **Facial Expressions** topic (+0.02) shows that smiling or joyful faces (animal or human) enhance warmth and sincerity.\n",
    "- Emotional expressiveness humanizes the campaign, strengthening donor connection.\n",
    "\n",
    "### Rescue Realism Performs Best When Paired with Hope\n",
    "- The **Shelter & Rescue Scenes** topic (+0.01) suggests that showing animals “in need” increases authenticity.\n",
    "- Works best when paired with positive transformation cues such as recovery or human-animal bonding.\n",
    "\n",
    "### Niche or Broad Animal Imagery Underperforms\n",
    "- Topics like **Cats** (–0.08) and **Farm Animals** (–0.02) correlated with lower fundraising outcomes, implying weaker donor connection to less-familiar species.\n",
    "- **Dogs & Birds** and **General Pet Aid** topics (≈0) had neutral effects, likely because such imagery feels generic or lacks emotional focus.\n",
    "\n",
    "---\n",
    "\n",
    "## Actionable Recommendations\n",
    "\n",
    "### A. Optimize Visual Storytelling\n",
    "- **Feature companion dogs prominently:** Use clear, high-quality images of dogs interacting with people or other animals.\n",
    "- **Show emotion:** Prioritize visuals with joyful or expressive faces.\n",
    "- **Balance realism with hope:** When using Shelter & Rescue Scenes, pair distress imagery with care or recovery moments.\n",
    "\n",
    "### B. Curate and Test Imagery\n",
    "- Maintain a mix:\n",
    "  - 70% emotional/expressive imagery (Dogs + Facial Expressions)\n",
    "  - 20% rescue context (Shelter & Rescue Scenes)\n",
    "  - ≤10% niche species (Cats or Farm Animals)\n",
    "- Use A/B testing to compare “smile-centric” vs. neutral thumbnails.\n",
    "\n",
    "### C. Strengthen Thematic Consistency\n",
    "- Align visuals with textual storytelling.\n",
    "- Emphasize **“joyful recovery,” “companionship,” or “second chances.”**\n",
    "- Avoid stock or overly generic images (e.g., those under Dogs & Birds or General Pet Aid without emotional cues).\n",
    "\n",
    "### D. Broaden Emotional Reach\n",
    "- Incorporate human-animal interaction photos (volunteers, adopters).\n",
    "- Use before-and-after rescue imagery to highlight transformation and build trust.\n",
    "\n",
    "\n",
    "## Summary\n",
    "Our analysis of ~1,000 GoFundMe animal-rescue campaigns using **LDA topic modeling** on image labels shows:\n",
    "\n",
    "- Fundraising success is tightly linked to **emotionally engaging and relatable imagery**.\n",
    "- Campaigns highlighting **dogs, expressive or smiling faces, and rescue-to-recovery stories** raised more funds than those with neutral or broad animal visuals (e.g., Dogs & Birds, General Pet Aid).\n",
    "- To maximize donor response, non-profits should emphasize **warm, hopeful storytelling** through imagery, depicting **connection, compassion, and transformation** rather than generic or impersonal content.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43256ece",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "acad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
